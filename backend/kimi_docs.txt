Use Kimi API to complete tool call (tool_calls)
Tool call, that is tool_calls, Transfer by function (ie function_call) Evolved, in certain specific contexts, or when reading some compatibility codes, you can also call the tool tool_calls And function transfer function_call Equivalent number, function call function_call Is a tool call tool_calls Subset.

What is tool call tool_calls
Tool call tool_calls The Kimi model was given the ability to perform specific actions. Kimi big model can talk and chat and answer questions raised by users. This is the ability of “ to say ”, and to call through tools tool_calls, Kimi big model also has the ability to do “ with ”, with the help of tool_calls, Kimi big model can help you search for Internet content, query databases, and even operate smart homes.

One tool call tool_calls Contains the following steps:

Use JSON Schema format definition tool;
through tools The parameters submit the defined tools to the Kimi big model, you can submit multiple tools at once;
The Kimi model will decide which tool or tools to use based on the context of the current chat, and the Kimi model may also choose not to use the tool;
The Kimi model will output the parameters and information required to call the tool in the JSON format;
Use the parameters of the Kimi model output, execute the corresponding tool, and submit the tool execution results to the Kimi model;
Kimi's large model gives users a reply based on the implementation results of the tool;
Reading the above steps, you may have such doubts:

Why does the Kimi big model itself not execute the tool, but also the tool parameters “ help ” Kimi big model execution tool generated by the Kimi big model? Since we are using execution tools, what does Kimi's big model do?

We will call with a practical tool tool_calls The case attempts to explain these issues to the reader.

through tool_calls Let Kimi big model have network query capabilities
The knowledge of the Kimi model comes from its training data. For some time-sensitive questions, the Kimi model cannot obtain answers from its existing knowledge. At this time, we hope that the Kimi model can search for the latest knowledge on the Internet by itself. And answer our questions based on this knowledge.

Definition tool
Imagine how we found the information we wanted on the Internet ourselves:

We will first open the search engine, such as Baidu or Bing, search the content we want in the search engine, then browse the search results, and decide which search result to click based on the website title and website introduction;
We may open one or more web pages of search results, browse the web pages and acquire the knowledge we need;
Looking back at our actions, we “ use the search engine search ” and “ to open the web page ” corresponding to the search results, and the tools we use are “ search engine ” and “ web browser ”, therefore, we need to abstract the tools corresponding to the JSOSchema model Let Kimi's big model also use search engines and browse web pages like humans.

Before that, let’s briefly introduce the JSON Schema format:

JSON Schemais a vocabulary that you can use to annotate and validate JSON documents.

JSON SchemaIt is a JSON document used to describe the JSON data format.

We define the following JSON Schema:

{
	"type": "object",
	"properties": {
		"name": {
			"type": "string"
		}
	}
}

This JSON Schema defines a JSON Object, which contains a name name And the type of field is string,e.g.

{
	"name": "Hei"
}

Using JSON Schema to describe our tool definition allows the Kimi model to know more clearly and intuitively what parameters our tool needs, as well as the type and introduction of each parameter. Next, let's define the two tools mentioned in the preceding “ search engine ” and “ web browser ”:

tools = [
	{
		"type": "function", # 约定的字段 type，目前支持 function 作为值
		"function": { # 当 type 为 function 时，使用 function 字段定义具体的函数内容
			"name": "search", # 函数的名称，请使用英文大小写字母、数据加上减号和下划线作为函数名称
			"description": """ 
				通过搜索引擎搜索互联网上的内容。
 
				当你的知识无法回答用户提出的问题，或用户请求你进行联网搜索时，调用此工具。请从与用户的对话中提取用户想要搜索的内容作为 query 参数的值。
				搜索结果包含网站的标题、网站的地址（URL）以及网站简介。
			""", # 函数的介绍，在这里写上函数的具体作用以及使用场景，以便 Kimi 大模型能正确地选择使用哪些函数
			"parameters": { # 使用 parameters 字段来定义函数接收的参数
				"type": "object", # 固定使用 type: object 来使 Kimi 大模型生成一个 JSON Object 参数
				"required": ["query"], # 使用 required 字段告诉 Kimi 大模型哪些参数是必填项
				"properties": { # properties 中是具体的参数定义，你可以定义多个参数
					"query": { # 在这里，key 是参数名称，value 是参数的具体定义
						"type": "string", # 使用 type 定义参数类型
						"description": """
							用户搜索的内容，请从用户的提问或聊天上下文中提取。
						""" # 使用 description 描述参数以便 Kimi 大模型更好地生成参数
					}
				}
			}
		}
	},
	{
		"type": "function", # 约定的字段 type，目前支持 function 作为值
		"function": { # 当 type 为 function 时，使用 function 字段定义具体的函数内容
			"name": "crawl", # 函数的名称，请使用英文大小写字母、数据加上减号和下划线作为函数名称
			"description": """
				根据网站地址（URL）获取网页内容。
			""", # 函数的介绍，在这里写上函数的具体作用以及使用场景，以便 Kimi 大模型能正确地选择使用哪些函数
			"parameters": { # 使用 parameters 字段来定义函数接收的参数
				"type": "object", # 固定使用 type: object 来使 Kimi 大模型生成一个 JSON Object 参数
				"required": ["url"], # 使用 required 字段告诉 Kimi 大模型哪些参数是必填项
				"properties": { # properties 中是具体的参数定义，你可以定义多个参数
					"url": { # 在这里，key 是参数名称，value 是参数的具体定义
						"type": "string", # 使用 type 定义参数类型
						"description": """
							需要获取内容的网站地址（URL），通常情况下从搜索结果中可以获取网站的地址。
						""" # 使用 description 描述参数以便 Kimi 大模型更好地生成参数
					}
				}
			}
		}
	}
]

When using the JSON Schema definition tool, we use the following fixed format to define a tool:

{
	"type": "function",
	"function": {
		"name": "NAME",
		"description": "DESCRIPTION",
		"parameters": {
			"type": "object",
			"properties": {
				
			}
		}
	}
}

among them,name,description,parameters.properties Defined by tool providers, where description Describes the specific role of the tool and where it is needed,parameters Describes the specific parameters required for successful call tools, including parameter types, parameter introduction, etc.;In the end, the Kimi model will generate a JSON Object that meets the definition requirements as a tool to call the parameters (arguments) according to the definition of JSON Schema.

Registration tool
Let's try search This tool is submitted to the Kimi big model to see if the Kimi big model can correctly call the tool:

from openai import OpenAI
 
 
client = OpenAI(
    api_key="MOONSHOT_API_KEY", # 在这里将 MOONSHOT_API_KEY 替换为你从 Kimi 开放平台申请的 API Key
    base_url="https://api.moonshot.cn/v1",
)
 
tools = [
	{
		"type": "function", # 约定的字段 type，目前支持 function 作为值
		"function": { # 当 type 为 function 时，使用 function 字段定义具体的函数内容
			"name": "search", # 函数的名称，请使用英文大小写字母、数据加上减号和下划线作为函数名称
			"description": """ 
				通过搜索引擎搜索互联网上的内容。
 
				当你的知识无法回答用户提出的问题，或用户请求你进行联网搜索时，调用此工具。请从与用户的对话中提取用户想要搜索的内容作为 query 参数的值。
				搜索结果包含网站的标题、网站的地址（URL）以及网站简介。
			""", # 函数的介绍，在这里写上函数的具体作用以及使用场景，以便 Kimi 大模型能正确地选择使用哪些函数
			"parameters": { # 使用 parameters 字段来定义函数接收的参数
				"type": "object", # 固定使用 type: object 来使 Kimi 大模型生成一个 JSON Object 参数
				"required": ["query"], # 使用 required 字段告诉 Kimi 大模型哪些参数是必填项
				"properties": { # properties 中是具体的参数定义，你可以定义多个参数
					"query": { # 在这里，key 是参数名称，value 是参数的具体定义
						"type": "string", # 使用 type 定义参数类型
						"description": """
							用户搜索的内容，请从用户的提问或聊天上下文中提取。
						""" # 使用 description 描述参数以便 Kimi 大模型更好地生成参数
					}
				}
			}
		}
	},
	# {
	# 	"type": "function", # 约定的字段 type，目前支持 function 作为值
	# 	"function": { # 当 type 为 function 时，使用 function 字段定义具体的函数内容
	# 		"name": "crawl", # 函数的名称，请使用英文大小写字母、数据加上减号和下划线作为函数名称
	# 		"description": """
	# 			根据网站地址（URL）获取网页内容。
	# 		""", # 函数的介绍，在这里写上函数的具体作用以及使用场景，以便 Kimi 大模型能正确地选择使用哪些函数
	# 		"parameters": { # 使用 parameters 字段来定义函数接收的参数
	# 			"type": "object", # 固定使用 type: object 来使 Kimi 大模型生成一个 JSON Object 参数
	# 			"required": ["url"], # 使用 required 字段告诉 Kimi 大模型哪些参数是必填项
	# 			"properties": { # properties 中是具体的参数定义，你可以定义多个参数
	# 				"url": { # 在这里，key 是参数名称，value 是参数的具体定义
	# 					"type": "string", # 使用 type 定义参数类型
	# 					"description": """
	# 						需要获取内容的网站地址（URL），通常情况下从搜索结果中可以获取网站的地址。
	# 					""" # 使用 description 描述参数以便 Kimi 大模型更好地生成参数
	# 				}
	# 			}
	# 		}
	# 	}
	# }
]
 
completion = client.chat.completions.create(
    model="moonshot-v1-8k",
    messages=[
        {"role": "system", "content": "你是 Kimi，由 Moonshot AI 提供的人工智能助手，你更擅长中文和英文的对话。你会为用户提供安全，有帮助，准确的回答。同时，你会拒绝一切涉及恐怖主义，种族歧视，黄色暴力等问题的回答。Moonshot AI 为专有名词，不可翻译成其他语言。"},
        {"role": "user", "content": "请联网搜索 Context Caching，并告诉我它是什么。"} # 在提问中要求 Kimi 大模型联网搜索
    ],
    temperature=0.3,
    tools=tools, # <-- 我们通过 tools 参数，将定义好的 tools 提交给 Kimi 大模型
)
 
print(completion.choices[0].model_dump_json(indent=4))

When the above code runs successfully, we get the return content of the Kimi model:

{
    "finish_reason": "tool_calls",
    "message": {
        "content": "",
        "role": "assistant",
        "tool_calls": [
            {
                "id": "search:0",
                "function": {
                    "arguments": "{\n    \"query\": \"Context Caching\"\n}",
                    "name": "search"
                },
                "type": "function",
            }
        ]
    }
}

Note that in this reply,finisht_reason The value is tool_callsThis means that it is not the response of the Kimi big model that this request returns, but the Kimi big model selection execution tool. You can pass finish_reason To judge whether the response of the current Kimi model is a tool call tool_calls.

in meessage section,content The field is empty, this is because it is currently being implemented tool_calls, The model did not generate user-oriented responses; at the same time it was added tool_calls field,tool_calls The field is a list, which contains all the tools to call this time, which also shows tool_calls Another feature of the, namely:The model can select multiple tools for call at once, either multiple different tools, or the same tool uses different parameters for call.tool_calls Each element in it represents a tool call, and the Kimi big model will generate a unique one for each tool call id,through function.name The field indicates the name of the currently executed tool function and places the execution parameters in function.arguments in,arguments The parameter is a legal sequenced JSON Obejct (extra,type The parameters are currently fixed values function).

Next, we should use the tools generated by the Kimi big model to call the parameters to perform specific tools.

Execution tool
The Kimi model will not help us execute the tool. We need to execute the parameters ourselves after receiving the parameters generated by the Kimi model. Before explaining how to execute the tool, let us answer the questions mentioned before:

Why does the Kimi big model itself not execute the tool, but also the tool parameters “ help ” Kimi big model execution tool generated by the Kimi big model? Since we are using execution tools, what does Kimi's big model do?

Let's imagine the application scene where we use the Kimi big model: We provide users with an intelligent robot based on the Kimi big model. There are three roles in this scene: users, robots, Kimi big models. The user asks the robot that the robot calls Kimi's large model API and returns the results of API to the user. When using tool_calls When the user asks the robot, the robot carries tools Call Kimi API, Kimi big model returns tool_calls Parameters, robot finished tool_calls, Submit the results again to Kimi API, Kimi big model generates news to return to users (finish_reason=stop), at this time the robot will return the news to the user. In the process,tool_calls The whole process is transparent and implicit for users.

Returning to the above question, as users, we are not actually using the execution tool, nor will we directly see the “ tool call from ”, but the robot that provides us with services is completing the tool call and will eventually produce the Kimi big model. The content of the reply is presented to us.

Let's explain how to implement the Kimi model back from the perspective of “ robot ” tool_calls:

from typing import *
 
import json
 
from openai import OpenAI
 
 
client = OpenAI(
    api_key="MOONSHOT_API_KEY", # 在这里将 MOONSHOT_API_KEY 替换为你从 Kimi 开放平台申请的 API Key
    base_url="https://api.moonshot.cn/v1",
)
 
tools = [
	{
		"type": "function", # 约定的字段 type，目前支持 function 作为值
		"function": { # 当 type 为 function 时，使用 function 字段定义具体的函数内容
			"name": "search", # 函数的名称，请使用英文大小写字母、数据加上减号和下划线作为函数名称
			"description": """ 
				通过搜索引擎搜索互联网上的内容。
 
				当你的知识无法回答用户提出的问题，或用户请求你进行联网搜索时，调用此工具。请从与用户的对话中提取用户想要搜索的内容作为 query 参数的值。
				搜索结果包含网站的标题、网站的地址（URL）以及网站简介。
			""", # 函数的介绍，在这里写上函数的具体作用以及使用场景，以便 Kimi 大模型能正确地选择使用哪些函数
			"parameters": { # 使用 parameters 字段来定义函数接收的参数
				"type": "object", # 固定使用 type: object 来使 Kimi 大模型生成一个 JSON Object 参数
				"required": ["query"], # 使用 required 字段告诉 Kimi 大模型哪些参数是必填项
				"properties": { # properties 中是具体的参数定义，你可以定义多个参数
					"query": { # 在这里，key 是参数名称，value 是参数的具体定义
						"type": "string", # 使用 type 定义参数类型
						"description": """
							用户搜索的内容，请从用户的提问或聊天上下文中提取。
						""" # 使用 description 描述参数以便 Kimi 大模型更好地生成参数
					}
				}
			}
		}
	},
	{
		"type": "function", # 约定的字段 type，目前支持 function 作为值
		"function": { # 当 type 为 function 时，使用 function 字段定义具体的函数内容
			"name": "crawl", # 函数的名称，请使用英文大小写字母、数据加上减号和下划线作为函数名称
			"description": """
				根据网站地址（URL）获取网页内容。
			""", # 函数的介绍，在这里写上函数的具体作用以及使用场景，以便 Kimi 大模型能正确地选择使用哪些函数
			"parameters": { # 使用 parameters 字段来定义函数接收的参数
				"type": "object", # 固定使用 type: object 来使 Kimi 大模型生成一个 JSON Object 参数
				"required": ["url"], # 使用 required 字段告诉 Kimi 大模型哪些参数是必填项
				"properties": { # properties 中是具体的参数定义，你可以定义多个参数
					"url": { # 在这里，key 是参数名称，value 是参数的具体定义
						"type": "string", # 使用 type 定义参数类型
						"description": """
							需要获取内容的网站地址（URL），通常情况下从搜索结果中可以获取网站的地址。
						""" # 使用 description 描述参数以便 Kimi 大模型更好地生成参数
					}
				}
			}
		}
	}
]
 
 
def search_impl(query: str) -> List[Dict[str, Any]]:
    """
    search_impl 使用搜索引擎对 query 进行搜索，目前主流的搜索引擎（例如 Bing）都提供了 API 调用方式，你可以自行选择
    你喜欢的搜索引擎 API 进行调用，并将返回结果中的网站标题、网站链接、网站简介信息放置在一个 dict 中返回。
 
    这里只是一个简单的示例，你可能需要编写一些鉴权、校验、解析的代码。
    """
    r = httpx.get("https://your.search.api", params={"query": query})
    return r.json()
 
 
def search(arguments: Dict[str, Any]) -> Any:
    query = arguments["query"]
    result = search_impl(query)
    return {"result": result}
 
 
def crawl_impl(url: str) -> str:
    """
    crawl_url 根据 url 获取网页上的内容。
 
    这里只是一个简单的示例，在实际的网页抓取过程中，你可能需要编写更多的代码来适配复杂的情况，例如异步加载的数据等；同时，在获取
    网页内容后，你可以根据自己的需要对网页内容进行清洗，只保留文本或移除不必要的内容（例如广告信息等）。
    """
    r = httpx.get(url)
    return r.text
 
 
def crawl(arguments: dict) -> str:
    url = arguments["url"]
    content = crawl_impl(url)
    return {"content": content}
 
 
# 通过 tool_map 将每个工具名称及其对应的函数进行映射，以便在 Kimi 大模型返回 tool_calls 时能快速找到应该执行的函数
tool_map = {
    "search": search,
    "crawl": crawl,
}
 
messages = [
    {"role": "system",
     "content": "你是 Kimi，由 Moonshot AI 提供的人工智能助手，你更擅长中文和英文的对话。你会为用户提供安全，有帮助，准确的回答。同时，你会拒绝一切涉及恐怖主义，种族歧视，黄色暴力等问题的回答。Moonshot AI 为专有名词，不可翻译成其他语言。"},
    {"role": "user", "content": "请联网搜索 Context Caching，并告诉我它是什么。"}  # 在提问中要求 Kimi 大模型联网搜索
]
 
finish_reason = None
 
# 我们的基本流程是，带着用户的问题和 tools 向 Kimi 大模型提问，如果 Kimi 大模型返回了 finish_reason: tool_calls，则我们执行对应的 tool_calls，
# 将执行结果以 role=tool 的 message 的形式重新提交给 Kimi 大模型，Kimi 大模型根据 tool_calls 结果进行下一步内容的生成：
#
#   1. 如果 Kimi 大模型认为当前的工具调用结果已经可以回答用户问题，则返回 finish_reason: stop，我们会跳出循环，打印出 message.content；
#   2. 如果 Kimi 大模型认为当前的工具调用结果无法回答用户问题，需要再次调用工具，我们会继续在循环中执行接下来的 tool_calls，直到 finish_reason 不再是 tool_calls；
#
# 在这个过程中，只有当 finish_reason 为 stop 时，我们才会将结果返回给用户。
 
while finish_reason is None or finish_reason == "tool_calls":
    completion = client.chat.completions.create(
        model="moonshot-v1-8k",
        messages=messages,
        temperature=0.3,
        tools=tools,  # <-- 我们通过 tools 参数，将定义好的 tools 提交给 Kimi 大模型
    )
    choice = completion.choices[0]
    finish_reason = choice.finish_reason
    if finish_reason == "tool_calls": # <-- 判断当前返回内容是否包含 tool_calls
        messages.append(choice.message) # <-- 我们将 Kimi 大模型返回给我们的 assistant 消息也添加到上下文中，以便于下次请求时 Kimi 大模型能理解我们的诉求
        for tool_call in choice.message.tool_calls: # <-- tool_calls 可能是多个，因此我们使用循环逐个执行
            tool_call_name = tool_call.function.name
            tool_call_arguments = json.loads(tool_call.function.arguments) # <-- arguments 是序列化后的 JSON Object，我们需要使用 json.loads 反序列化一下
            tool_function = tool_map[tool_call_name] # <-- 通过 tool_map 快速找到需要执行哪个函数
            tool_result = tool_function(tool_call_arguments)
 
            # 使用函数执行结果构造一个 role=tool 的 message，以此来向模型展示工具调用的结果；
            # 注意，我们需要在 message 中提供 tool_call_id 和 name 字段，以便 Kimi 大模型
            # 能正确匹配到对应的 tool_call。
            messages.append({
                "role": "tool",
                "tool_call_id": tool_call.id,
                "name": tool_call_name,
                "content": json.dumps(tool_result), # <-- 我们约定使用字符串格式向 Kimi 大模型提交工具调用结果，因此在这里使用 json.dumps 将执行结果序列化成字符串
            })
 
print(choice.message.content) # <-- 在这里，我们才将模型生成的回复返回给用户

We use while circulating to perform code logic including tool calls, because the Kimi model usually does not perform tool calls only once, especially to search this scene online. Usually, the Kimi model will choose to call first. search Tools, through search After the tool obtains the search results, call again crawl The tool will search the results url Converted to specific web content, the overall messages structure is as follows:

system: prompt                                                                                               # 系统提示词
user: prompt                                                                                                 # 用户提问
assistant: tool_call(name=search, arguments={query: query})                                                  # Kimi 大模型返回 tool_call 调用（单个）                            
tool: search_result(tool_call_id=tool_call.id, name=search)                                                  # 提交 tool_call 执行结果
assistant: tool_call_1(name=crawl, arguments={url: url_1}), tool_call_2(name=crawl, arguments={url: url_2})  # Kimi 大模型继续返回 tool_calls 调用（多个）
tool: crawl_content(tool_call_id=tool_call_1.id, name=crawl)                                                 # 提交 tool_call_1 执行结果
tool: crawl_content(tool_call_id=tool_call_2.id, name=crawl)                                                 # 提交 tool_call_2 执行结果
assistant: message_content(finish_reason=stop)                                                               # Kimi 大模型生成面向用户的回复消息，本轮对话结束

So far, we have completed the whole process of “ networking query ” tool call, if you realize your own search with crawl Method, then when you ask the Kimi big model for networking, it will call search with crawl Two tools, and give you the correct response based on the results of the tool call.

Common problems and precautions
About fluid output
Under the stream mode,tool_calls The same applies, but there are some areas that require additional attention, listed below:

During the flow output, due to finish_reason Will appear in the last data block, so it is recommended to use delta.tool_calls Whether the field exists to determine whether the current response includes tool calls;
During the flow output, it will be exported first delta.contentAnd then output delta.tool_callsSo you have to wait delta.content Judgment and identification can only be achieved after the output is completed tool_calls;
During the flow output, we will indicate the current call in the initial data block tool_calls of tool_call.id with tool_call.function.name, Will only export in subsequent data blocks tool_call.function.arguments;
During the flow output, if the Kimi big model returns multiple at one time tool_callsThen we will use an additional name index To mark the current tool_call Index so that you can stitch it correctly tool_call.function.arguments Parameters, we use the code example in the flow output chapter (in the case where SDK is not used) to explain how to operate:
import os
import json
import httpx  # 我们使用 httpx 库来执行我们的 HTTP 请求
 
tools = [
    {
        "type": "function",  # 约定的字段 type，目前支持 function 作为值
        "function": {  # 当 type 为 function 时，使用 function 字段定义具体的函数内容
            "name": "search",  # 函数的名称，请使用英文大小写字母、数据加上减号和下划线作为函数名称
            "description": """ 
				通过搜索引擎搜索互联网上的内容。
 
				当你的知识无法回答用户提出的问题，或用户请求你进行联网搜索时，调用此工具。请从与用户的对话中提取用户想要搜索的内容作为 query 参数的值。
				搜索结果包含网站的标题、网站的地址（URL）以及网站简介。
			""",  # 函数的介绍，在这里写上函数的具体作用以及使用场景，以便 Kimi 大模型能正确地选择使用哪些函数
            "parameters": {  # 使用 parameters 字段来定义函数接收的参数
                "type": "object",  # 固定使用 type: object 来使 Kimi 大模型生成一个 JSON Object 参数
                "required": ["query"],  # 使用 required 字段告诉 Kimi 大模型哪些参数是必填项
                "properties": {  # properties 中是具体的参数定义，你可以定义多个参数
                    "query": {  # 在这里，key 是参数名称，value 是参数的具体定义
                        "type": "string",  # 使用 type 定义参数类型
                        "description": """
							用户搜索的内容，请从用户的提问或聊天上下文中提取。
						"""  # 使用 description 描述参数以便 Kimi 大模型更好地生成参数
                    }
                }
            }
        }
    },
]
 
header = {
    "Content-Type": "application/json",
    "Authorization": f"Bearer {os.environ.get('MOONSHOT_API_KEY')}",
}
 
data = {
    "model": "moonshot-v1-128k",
    "messages": [
        {"role": "user", "content": "请联网搜索 Context Caching 技术。"}
    ],
    "temperature": 0.3,
    "stream": True,
    "n": 2,  # <-- 注意这里，我们要求 Kimi 大模型输出 2 个回复
    "tools": tools,  # <-- 添加工具调用
}
 
# 使用 httpx 向 Kimi 大模型发出 chat 请求，并获得响应 r
r = httpx.post("https://api.moonshot.cn/v1/chat/completions",
               headers=header,
               json=data)
if r.status_code != 200:
    raise Exception(r.text)
 
data: str
 
# 在这里，我们预先构建一个 List，用于存放不同的回复消息，由于我们设置了 n=2，因此我们将 List 初始化为 2 个元素
messages = [{}, {}]
 
# 在这里，我们使用了 iter_lines 方法来逐行读取响应体
for line in r.iter_lines():
    # 去除每一行收尾的空格，以便更好地处理数据块
    line = line.strip()
 
    # 接下来我们要处理三种不同的情况：
    #   1. 如果当前行是空行，则表明前一个数据块已接收完毕（即前文提到的，通过两个换行符结束数据块传输），我们可以对该数据块进行反序列化，并打印出对应的 content 内容；
    #   2. 如果当前行为非空行，且以 data: 开头，则表明这是一个数据块传输的开始，我们去除 data: 前缀后，首先判断是否是结束符 [DONE]，如果不是，将数据内容保存到 data 变量；
    #   3. 如果当前行为非空行，但不以 data: 开头，则表明当前行仍然归属上一个正在传输的数据块，我们将当前行的内容追加到 data 变量尾部；
 
    if len(line) == 0:
        chunk = json.loads(data)
 
        # 通过循环获取每个数据块中所有的 choice，并获取 index 对应的 message 对象
        for choice in chunk["choices"]:
            index = choice["index"]
            message = messages[index]
            usage = choice.get("usage")
            if usage:
                message["usage"] = usage
            delta = choice["delta"]
            role = delta.get("role")
            if role:
                message["role"] = role
            content = delta.get("content")
            if content:
            	if "content" not in message:
            		message["content"] = content
            	else:
                	message["content"] = message["content"] + content
 
            # 从这里，我们开始处理 tool_calls
            tool_calls = delta.get("tool_calls")  # <-- 先判断数据块中是否包含 tool_calls
            if tool_calls:
                if "tool_calls" not in message:
                    message["tool_calls"] = []  # <-- 如果包含 tool_calls，我们初始化一个列表来保存这些 tool_calls，注意此时的列表中没有任何元素，长度为 0
                for tool_call in tool_calls:
                    tool_call_index = tool_call["index"]  # <-- 获取当前 tool_call 的 index 索引
                    if len(message["tool_calls"]) < (
                            tool_call_index + 1):  # <-- 根据 index 索引扩充 tool_calls 列表，以便于我们能通过下标访问到对应的 tool_call
                        message["tool_calls"].extend([{}] * (tool_call_index + 1 - len(message["tool_calls"])))
                    tool_call_object = message["tool_calls"][tool_call_index]  # <-- 根据下标访问对应的 tool_call
                    tool_call_object["index"] = tool_call_index
 
                    # 下面的步骤，是根据数据块中的信息填充每个 tool_call 的 id、type、function 字段
                    # 在 function 字段中，又包括 name 和 arguments 字段，arguments 字段会由每个数据块
                    # 依次补充，如同 delta.content 字段一般。
 
                    tool_call_id = tool_call.get("id")
                    if tool_call_id:
                        tool_call_object["id"] = tool_call_id
                    tool_call_type = tool_call.get("type")
                    if tool_call_type:
                        tool_call_object["type"] = tool_call_type
                    tool_call_function = tool_call.get("function")
                    if tool_call_function:
                        if "function" not in tool_call_object:
                            tool_call_object["function"] = {}
                        tool_call_function_name = tool_call_function.get("name")
                        if tool_call_function_name:
                            tool_call_object["function"]["name"] = tool_call_function_name
                        tool_call_function_arguments = tool_call_function.get("arguments")
                        if tool_call_function_arguments:
                            if "arguments" not in tool_call_object["function"]:
                                tool_call_object["function"]["arguments"] = tool_call_function_arguments
                            else:
                                tool_call_object["function"]["arguments"] = tool_call_object["function"][
                                                                            "arguments"] + tool_call_function_arguments  # <-- 依次补充 function.arguments 字段的值
                    message["tool_calls"][tool_call_index] = tool_call_object
 
            data = ""  # 重置 data
    elif line.startswith("data: "):
        data = line.lstrip("data: ")
 
        # 当数据块内容为 [DONE] 时，则表明所有数据块已发送完毕，可断开网络连接
        if data == "[DONE]":
            break
    else:
        data = data + "\n" + line  # 我们仍然在追加内容时，为其添加一个换行符，因为这可能是该数据块有意将数据分行展示
 
# 在组装完所有 messages 后，我们分别打印其内容
for index, message in enumerate(messages):
    print("index:", index)
    print("message:", json.dumps(message, ensure_ascii=False))
    print("")

The following is the use of openai SDK to process flow output tool_calls Code example:

import os
import json
 
from openai import OpenAI
 
client = OpenAI(
    api_key=os.environ.get("MOONSHOT_API_KEY"),
    base_url="https://api.moonshot.cn/v1",
)
 
tools = [
    {
        "type": "function",  # 约定的字段 type，目前支持 function 作为值
        "function": {  # 当 type 为 function 时，使用 function 字段定义具体的函数内容
            "name": "search",  # 函数的名称，请使用英文大小写字母、数据加上减号和下划线作为函数名称
            "description": """ 
				通过搜索引擎搜索互联网上的内容。
 
				当你的知识无法回答用户提出的问题，或用户请求你进行联网搜索时，调用此工具。请从与用户的对话中提取用户想要搜索的内容作为 query 参数的值。
				搜索结果包含网站的标题、网站的地址（URL）以及网站简介。
			""",  # 函数的介绍，在这里写上函数的具体作用以及使用场景，以便 Kimi 大模型能正确地选择使用哪些函数
            "parameters": {  # 使用 parameters 字段来定义函数接收的参数
                "type": "object",  # 固定使用 type: object 来使 Kimi 大模型生成一个 JSON Object 参数
                "required": ["query"],  # 使用 required 字段告诉 Kimi 大模型哪些参数是必填项
                "properties": {  # properties 中是具体的参数定义，你可以定义多个参数
                    "query": {  # 在这里，key 是参数名称，value 是参数的具体定义
                        "type": "string",  # 使用 type 定义参数类型
                        "description": """
							用户搜索的内容，请从用户的提问或聊天上下文中提取。
						"""  # 使用 description 描述参数以便 Kimi 大模型更好地生成参数
                    }
                }
            }
        }
    },
]
 
completion = client.chat.completions.create(
    model="moonshot-v1-128k",
    messages=[
        {"role": "user", "content": "请联网搜索 Context Caching 技术。"}
    ],
    temperature=0.3,
    stream=True,
    n=2,  # <-- 注意这里，我们要求 Kimi 大模型输出 2 个回复
    tools=tools,  # <-- 添加工具调用
)
 
# 在这里，我们预先构建一个 List，用于存放不同的回复消息，由于我们设置了 n=2，因此我们将 List 初始化为 2 个元素
messages = [{}, {}]
 
for chunk in completion:
    # 通过循环获取每个数据块中所有的 choice，并获取 index 对应的 message 对象
    for choice in chunk.choices:
        index = choice.index
        message = messages[index]
        delta = choice.delta
        role = delta.role
        if role:
            message["role"] = role
        content = delta.content
        if content:
        	if "content" not in message:
        		message["content"] = content
        	else:
            	message["content"] = message["content"] + content
 
        # 从这里，我们开始处理 tool_calls
        tool_calls = delta.tool_calls  # <-- 先判断数据块中是否包含 tool_calls
        if tool_calls:
            if "tool_calls" not in message:
                message["tool_calls"] = []  # <-- 如果包含 tool_calls，我们初始化一个列表来保存这些 tool_calls，注意此时的列表中没有任何元素，长度为 0
            for tool_call in tool_calls:
                tool_call_index = tool_call.index  # <-- 获取当前 tool_call 的 index 索引
                if len(message["tool_calls"]) < (
                        tool_call_index + 1):  # <-- 根据 index 索引扩充 tool_calls 列表，以便于我们能通过下标访问到对应的 tool_call
                    message["tool_calls"].extend([{}] * (tool_call_index + 1 - len(message["tool_calls"])))
                tool_call_object = message["tool_calls"][tool_call_index]  # <-- 根据下标访问对应的 tool_call
                tool_call_object["index"] = tool_call_index
 
                # 下面的步骤，是根据数据块中的信息填充每个 tool_call 的 id、type、function 字段
                # 在 function 字段中，又包括 name 和 arguments 字段，arguments 字段会由每个数据块
                # 依次补充，如同 delta.content 字段一般。
 
                tool_call_id = tool_call.id
                if tool_call_id:
                    tool_call_object["id"] = tool_call_id
                tool_call_type = tool_call.type
                if tool_call_type:
                    tool_call_object["type"] = tool_call_type
                tool_call_function = tool_call.function
                if tool_call_function:
                    if "function" not in tool_call_object:
                        tool_call_object["function"] = {}
                    tool_call_function_name = tool_call_function.name
                    if tool_call_function_name:
                        tool_call_object["function"]["name"] = tool_call_function_name
                    tool_call_function_arguments = tool_call_function.arguments
                    if tool_call_function_arguments:
                        if "arguments" not in tool_call_object["function"]:
                            tool_call_object["function"]["arguments"] = tool_call_function_arguments
                        else:
                            tool_call_object["function"]["arguments"] = tool_call_object["function"][
                                                                            "arguments"] + tool_call_function_arguments  # <-- 依次补充 function.arguments 字段的值
                message["tool_calls"][tool_call_index] = tool_call_object
 
# 在组装完所有 messages 后，我们分别打印其内容
for index, message in enumerate(messages):
    print("index:", index)
    print("message:", json.dumps(message, ensure_ascii=False))
    print("")

about tool_calls with function_call
tool_calls Yes function_call Advanced version, since openai has function_call Etc. parameters functions) Marked as “ abandoned ”, so our API will no longer support function_call. You can consider using tool_calls instead function_call, Compared to function_call,tool_calls There are several advantages:

Support parallel calls, Kimi big model can return multiple at a time tool_calls, You can call these at the same time in a concurrent way in the code tool_call To reduce time consumption;
For those who are not dependent tool_calls, Kimi's large model will also tend to be called in parallel, which is compared to the original order function_call, To a certain extent reduced Tokens consumption;
about content
Using tools to call tool_calls In the process, you may find that finish_reason=tool_calls In case, occasionally message.content The field is not empty, usually here content The content is that the Kimi model is explaining which tools need to be called and why they need to be called. Its significance is that if your tool calling process takes a long time, or if you need to call multiple tools in series to complete a round of conversation, then giving the user a descriptive statement before calling the tool can reduce the user’s waiting anxiety or dissatisfaction, at the same time, explain to the user which tools are currently called and why the tools are called, It also helps users understand the process of the entire tool call, and promptly give intervention and correction (for example, users think that the current tool selection error can terminate the tool call in time, or the tool selection through the prompt correction model in the next round of conversation).

About Tokens
tools The content in the parameters will also be calculated in the total Tokens, please make sure tools,messages The total number of Tokens in does not exceed the size of the model's context window.

About the layout
In the scene of using tools, our message is no longer:

system: ...
user: ...
assistant: ...
user: ...
assistant: ...

In this arrangement, it will become like

system: ...
user: ...
assistant: ...
tool: ...
tool: ...
assistant: ...

Such a arrangement, it should be noted that when Kimi’s big model is generated tool_calls Please make sure every tool_call Have corresponding role=tool Of message, and this message is set correctly tool_call_idif role=tool Of messages tool_calls Inconsistent numbers can cause errors; if role=tool Of messages tool_call_id with tool_calls Among tool_call.id Failure to correspond will also lead to errors.

If you meet tool_call_id not found error
If you meet tool_call_id not found Wrong, probably because you did not return Kimi API role=assistant The message is added to the messages list, and the correct message sequence should look like this:

system: ...
user: ...
assistant: ...  # <-- 也许你并未将这一条 assistant message 添加到 messages 列表中
tool: ...
tool: ...
assistant: ...

You can execute every time you receive Kimi API's return value messages.append(message) To add the news of Kimi API's return to the list of messages to avoid appearing tool_call_id not found error.

Note: Add to messages List is located role=tool The former assistant messages must fully include Kimi API's return tool_calls Terms and phrases. We recommend returning Kimi API directly choice.message “The original intact ” is added to the messages list to avoid possible errors.





Use Kimi API's network search function
In the previous chapter (Use Kimi API to complete tool call), we detailed how to call through Kimi API tools tool_calls Feature completes the network search function of Kimi's large model. Let's review the content of the previous implementation process:

Using the JSON Schema format definition tool, we defined it on the occasion of online search search with crawl Two tools;
through tools The parameters will be defined search with crawl Submit to Kimi big model;
Kimi big model will choose to call based on the context of the current chat search with crawlAnd generate relevant parameters to output in the JSON format;
Use the parameters of Kimi's large model output to execute search with crawl Function and submit the function execution results to Kimi model;
Kimi's large model gives users a reply based on the implementation results of the tool;
In the process of achieving a networked search, we need to realize it ourselves search with crawl Function, which may include:

Call the search engine interface, or perform content search by yourself;
Obtain search results, including URL and abstract information;
Obtaining web content according to URL may require different reading rules for different websites;
Wash and organize the acquired web content into a model-friendly format, such as Markdown;
Handle various errors and abnormal situations, such as no search results, failure to obtain web content, etc.;
The realization of these steps is generally considered cumbersome and challenging. Our users have repeatedly proposed that we want a simple, convenient, unpacked “ network search ” function; therefore, we are based on the original Kimi model. Tool call tool_calls The usage provides a tool function built by Kimi builtin_function.$web_searchTo achieve a network search function.

$web_search The basic usage and process of functions and the usual tool call tool_calls Same, but there are still some small differences, we will explain in detail how to call Kimi’s built-in $web_search The function realizes the network search function, and marks the items that require additional attention in the codes and instructions.

$web_searchstatement
With ordinary tool Different,$web_search The function does not need to provide specific parameter descriptions, only needs to tools In the statement type with function.name Successful registration $web_search function:

tools = [
	{
		"type": "builtin_function",  # <-- 我们使用 builtin_function 来表示 Kimi 内置工具，也用于区分普通 function
		"function": {
			"name": "$web_search",
		},
	},
]

$web_search In USD $ As a prefix, this is an expression of our agreed function of Kimi(In ordinary function In the definition, the dollar symbol is not allowed $), if there are other Kimi built-in functions, they will also be symbolized in US dollars $ As a prefix.

In the statement tools time,$web_search Can be with other ordinary function Coexist, further,builtin_function With ordinary function Can coexist, you can tools Add both builtin_funciont, And add ordinary functionOr add at the same time builtin_function And ordinary function.

Next, let us transform the original tool_calls Code to explain how to execute tool_calls.

$web_searchcarried out
The following is after transformation tool_calls code:

from typing import *
 
import os
import json
 
from openai import OpenAI
from openai.types.chat.chat_completion import Choice
 
client = OpenAI(
    base_url="https://api.moonshot.cn/v1",
    api_key=os.environ.get("MOONSHOT_API_KEY"),
)
 
 
# search 工具的具体实现，这里我们只需要返回参数即可
def search_impl(arguments: Dict[str, Any]) -> Any:
    """
    在使用 Moonshot AI 提供的 search 工具的场合，只需要原封不动返回 arguments 即可，
    不需要额外的处理逻辑。
 
    但如果你想使用其他模型，并保留联网搜索的功能，那你只需要修改这里的实现（例如调用搜索
    和获取网页内容等），函数签名不变，依然是 work 的。
 
    这最大程度保证了兼容性，允许你在不同的模型间切换，并且不需要对代码有破坏性的修改。
    """
    return arguments
 
 
def chat(messages) -> Choice:
    completion = client.chat.completions.create(
        model="moonshot-v1-128k",
        messages=messages,
        temperature=0.3,
        tools=[
            {
                "type": "builtin_function",  # <-- 使用 builtin_function 声明 $web_search 函数，请在每次请求都完整地带上 tools 声明
                "function": {
                    "name": "$web_search",
                },
            }
        ]
    )
    return completion.choices[0]
 
 
def main():
    messages = [
        {"role": "system", "content": "你是 Kimi。"},
    ]
 
    # 初始提问
    messages.append({
        "role": "user",
        "content": "请搜索 Moonshot AI Context Caching 技术，并告诉我它是什么。"
    })
 
    finish_reason = None
    while finish_reason is None or finish_reason == "tool_calls":
        choice = chat(messages)
        finish_reason = choice.finish_reason
        if finish_reason == "tool_calls":  # <-- 判断当前返回内容是否包含 tool_calls
            messages.append(choice.message)  # <-- 我们将 Kimi 大模型返回给我们的 assistant 消息也添加到上下文中，以便于下次请求时 Kimi 大模型能理解我们的诉求
            for tool_call in choice.message.tool_calls:  # <-- tool_calls 可能是多个，因此我们使用循环逐个执行
                tool_call_name = tool_call.function.name
                tool_call_arguments = json.loads(tool_call.function.arguments)  # <-- arguments 是序列化后的 JSON Object，我们需要使用 json.loads 反序列化一下
                if tool_call_name == "$web_search":
                    tool_result = search_impl(tool_call_arguments)
                else:
                    tool_result = f"Error: unable to find tool by name '{tool_call_name}'"
 
                # 使用函数执行结果构造一个 role=tool 的 message，以此来向模型展示工具调用的结果；
                # 注意，我们需要在 message 中提供 tool_call_id 和 name 字段，以便 Kimi 大模型
                # 能正确匹配到对应的 tool_call。
                messages.append({
                    "role": "tool",
                    "tool_call_id": tool_call.id,
                    "name": tool_call_name,
                    "content": json.dumps(tool_result),  # <-- 我们约定使用字符串格式向 Kimi 大模型提交工具调用结果，因此在这里使用 json.dumps 将执行结果序列化成字符串
                })
 
    print(choice.message.content)  # <-- 在这里，我们才将模型生成的回复返回给用户
 
 
if __name__ == '__main__':
    main()

Looking back at the above code, we were surprised to find that it is in use $web_search When functioning, its basic process and ordinary function There is no difference, developers can even call without modifying the original execution tool tool_calls Code. And the difference and especially special thing is that we are realizing search_impl At the function, there is not much logic for searching, analyzing, and obtaining web content. We simply generate the parameters generated by the Kimi big model tool_call.function.arguments You can complete the tool call without moving back tool_calls,Why is this?

In fact, as builtin_function As the name indicates,$web_search It is the function built in the Kimi big model, which is defined by the Kimi big model and also executed by the Kimi big model. The process is:

When Kimi's big model was born finish_reason=tool_calls In response, it was shown that the Kimi model is aware of the current need to implement $web_search Function, and has also been implemented $web_search All preparations;
Kimi big model will take the parameters necessary to perform the function to tool_call.function.arguments The form is returned to the caller, but these parameters are not performed by the caller, the caller only needs to tool_call.function.arguments Submit the Kimi large model intact, that is, the Kimi large model can perform the corresponding networked search process;
When the user will tool_call.function.arguments use role=tool of message At the time of submission, the Kimi model immediately began to implement a networked search process and generated news that users could read based on the search and reading results, namely finish_reason=stop of message;
Notes on compatibility
Kimi API provides a networked search function designed to provide a highly reliable large model networked search solution without destroying the original compatibility of API and SDK, which is fully compatible with the original tool call of the Kimi big model tool_calls Features, which means:When you want to switch from the network search function provided by Kimi to the network search function you realize, you only need a simple two-step change to complete it without destroying the overall structure of the code:

will $web_search of tool The definition is modified to your own tool Definition (including name,description Wait), this may need to be tool.function Add additional explanatory information to inform the model of what parameters need to be generated, you can parameters Add any parameter information you need in the field;
modify search_impl The realization of the function is using Kimi $web_search At the time, you just need to return to the entrance intact arguments Yes, but if you use your own network search service, you may need to fully realize what was mentioned at the beginning of the article search with crawl Function
After completing the above steps, you have successfully completed all matters from the network search function provided by Kimi to the network search function you have realized.

About Tokens consumption
Using the networking search function provided by Kimi $web_search At the time, the search results will also be included in the Tokens occupied by the prompts (ie prompt_tokens). Normally, because the results of the network search contain a lot of content, the final consumption of Tokens will be more. In order to avoid consuming a lot of Tokens without knowing, we are generating $web_search Functional parameters arguments When, an additional one will be added total_tokens The field is used to inform the caller that the total number of Tokens occupied by this search will be included in the total number of Tokens when you complete the entire network search process prompt_tokens In, we will use specific codes to show how to obtain these Tokens consumption:

from typing import *
 
import os
import json
 
from openai import OpenAI
from openai.types.chat.chat_completion import Choice
 
 
client = OpenAI(
    base_url="https://api.moonshot.cn/v1",
    api_key=os.environ.get("MOONSHOT_API_KEY"),
)
 
 
# search 工具的具体实现，这里我们只需要返回参数即可
def search_impl(arguments: Dict[str, Any]) -> Any:
    """
    在使用 Moonshot AI 提供的 search 工具的场合，只需要原封不动返回 arguments 即可，
    不需要额外的处理逻辑。
 
    但如果你想使用其他模型，并保留联网搜索的功能，那你只需要修改这里的实现（例如调用搜索
    和获取网页内容等），函数签名不变，依然是 work 的。
 
    这最大程度保证了兼容性，允许你在不同的模型间切换，并且不需要对代码有破坏性的修改。
    """
    return arguments
 
 
def chat(messages) -> Choice:
    completion = client.chat.completions.create(
        model="moonshot-v1-128k",
        messages=messages,
        temperature=0.3,
        tools=[
            {
                "type": "builtin_function",
                "function": {
                    "name": "$web_search",
                },
            }
        ]
    )
    usage = completion.usage
    choice = completion.choices[0]
 
    # =========================================================================
    # 通过判断 finish_reason = stop，我们将完成联网搜索流程后，消耗的 Tokens 打印出来
    if choice.finish_reason == "stop":
        print(f"chat_prompt_tokens:          {usage.prompt_tokens}")
        print(f"chat_completion_tokens:      {usage.completion_tokens}")
        print(f"chat_total_tokens:           {usage.total_tokens}")
    # =========================================================================
 
    return choice
 
 
def main():
    messages = [
        {"role": "system", "content": "你是 Kimi。"},
    ]
 
    # 初始提问
    messages.append({
        "role": "user",
        "content": "请搜索 Moonshot AI Context Caching 技术，并告诉我它是什么。"
    })
 
    finish_reason = None
    while finish_reason is None or finish_reason == "tool_calls":
        choice = chat(messages)
        finish_reason = choice.finish_reason
        if finish_reason == "tool_calls":
            messages.append(choice.message)
            for tool_call in choice.message.tool_calls:
                tool_call_name = tool_call.function.name
                tool_call_arguments = json.loads(
                    tool_call.function.arguments)
                if tool_call_name == "$web_search":
 
    				# ===================================================================
                    # 我们将联网搜索过程中，由联网搜索结果产生的 Tokens 打印出来
                    search_content_total_tokens = tool_call_arguments.get("usage", {}).get("total_tokens")
                    print(f"search_content_total_tokens: {search_content_total_tokens}")
    				# ===================================================================
 
                    tool_result = search_impl(tool_call_arguments)
                else:
                    tool_result = f"Error: unable to find tool by name '{tool_call_name}'"
 
                messages.append({
                    "role": "tool",
                    "tool_call_id": tool_call.id,
                    "name": tool_call_name,
                    "content": json.dumps(tool_result),
                })
 
    print(choice.message.content)
 
 
if __name__ == '__main__':
    main()
 

Implement the above code and obtain the following return results:

search_content_total_tokens: 13046  # <-- 代表由于触发了联网搜索动作，产生的联网搜索结果占用的 Tokens 数
chat_prompt_tokens:          13212  # <-- 代表包含了联网搜索结果的输入 Tokens 数量
chat_completion_tokens:      295    # <-- 代表 Kimi 大模型根据联网搜索结果生成的 Tokens 数量
chat_total_tokens:           13507  # <-- 代表包含了联网搜索流程的请求消耗的总 Tokens 数量
 
# 此处省略 Kimi 大模型根据联网搜索结果生成的内容

Choice about model size
Another problem that comes with it is that when the network search function is activated, the number of Tokens has changed significantly, beyond the original model context window, which is likely to trigger a Input token length too long Misreporting information. Therefore, when using the network search function, we suggest to choose a dynamic model moonshot-v1-autoTo adapt to the changes in Tokens, we changed slightly chat Correspondence code to use moonshot-v1-auto model:

def chat(messages) -> Choice:
    completion = client.chat.completions.create(
        model="moonshot-v1-auto",  # <-- 我们使用 moonshot-v1-auto 来适应 Tokens 动态变化的场景，
                                   #     在初始提问时，使用 moonshot-v1-8k 模型，在获取搜索内容后，如
                                   #     果 Tokens 数量超过 8k，则会自动选择 moonshot-v1-32k 或 
                                   #     moonshot-v1-128k 模型。
        messages=messages,
        temperature=0.3,
        tools=[
            {
                "type": "builtin_function",  # <-- 使用 builtin_function 声明 $web_search 函数，请在每次请求都完整地带上 tools 声明
                "function": {
                    "name": "$web_search",
                },
            }
        ]
    )
    return completion.choices[0]

About other tools
$web_search tools can be mixed with other ordinary tools, you can freely combine type=builtin_function with type=function Tools.

About network search billing
In addition to Tokens consumption, we will also charge a call fee for each network search at ￥0.03, please see for detailsbilling.